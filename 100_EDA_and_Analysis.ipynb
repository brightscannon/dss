{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ■ 초기 데이터 분석\n",
    "\n",
    "### 1. EDA(Exploratory Data Analysis) - 탐색적 자료 분석\n",
    "- 데이터의 \"특징\"과 내재적인 \"구조\"적 관계를 알아보기 위한 기법\n",
    "\n",
    "\n",
    ">- 의도\n",
    "    - 이론적 모형 적용 --> 데이터를 있는그대로 보겨는데 중점\n",
    ">- 자료의 구조 특징 파악을 위해\n",
    "    - 자료의 요약, 그래프 기법 활용\n",
    ">- 결론 (중요도, 강조)\n",
    "    - 추론통계학보다는 기술통계학에 중점\n",
    "\n",
    "### 2. 자료요약, 그래프화에 활용하는 방법\n",
    "- 중앙값을 평균보다도 중요하게 사용함(cuz : median은 outlier에 영향을 적게 받는다)\n",
    "- 세심한 관찰 -> 실험 -> 분석의 반복 --> insight를 얻는것이 중요하다.\n",
    "- 탐험정신, 도전, 해당분야의 전문가와 협업이 강조된다.\n",
    "\n",
    "### 3. EDA의 4가지 큰 주제\n",
    "1. 저항성(resistance) : 손상,오류,outlier의 영향을 적게 받아야함\n",
    "2. 잔차해석(residual) : 관찰값들이 주 경향에서 얼마나 벗어나는지 분석\n",
    "3. 자료재표현(re-expression) : 다른 방식의 표현(로그, 제곱, 역수변환 등의 과정)\n",
    "4. 자료의 현시성(Graphical-representation) : 시각적 표현(그래프, 애니메이션 등) -- 줄기, 잎 그림, boxplot 등\n",
    "\n",
    ">- 로그, 제곱, 역수 등 적용하여\n",
    "    - 분포선 형성, 분산 안정성, 분포대칭성 등이 높아지도록 함수 적용하고\n",
    "    - 정규분포가 나타나는 분포를 만들 수 있는지도 확인해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "\n",
    "# ■ 첫발표때 얻은 것\n",
    "\n",
    "### walmart analysis 2: sales in stormy weather (◆ 표시는 박사님 피드백)\n",
    "- 발표시작(개요) - 분석목적\n",
    "    - 모델성능(결과) 보여줌\n",
    "    - 평가방법 소개 --> ◆ 1. 실제로 아이템 재고에 대한 증명이 데이터분석으로 가능한지를 물어봄 (의도가 사실인지를 확인) \n",
    "    - 명제/수식설명 --> ◆ 2. 시각적 자료 요구, ◆ 3. (e)오타지적함\n",
    "    - 주요 변수설명 --> ◆ 4. R2값에 대해 물어본 뒤 이전 발표팀과 비교함, ◆ 5. 너무 긴 설명에 대해 지적함\n",
    "\n",
    "- 발표중반(분석부) :\n",
    "    - EDA : 변수 전처리 및 새 지표생성\n",
    "    - 변수 특징 탐색 : 계절성, 기간성, NaN값\n",
    "    - 강우량 및 강설량 : 구간별 등급설정 --> ◆ 6. 카테고리화한 사실을 확인 후 다른팀도 카테고리화 했는지 비교.\n",
    "    - 판매되는 기간적특징을 plot과 함께 설명 \n",
    "        - --> ◆ 7. 구조적 변화에 대한 설명(상황이 변했다), - 다른 확률변수의 등장, 정량적 증명을 생각할 필요가 있었음을 말해줌. ◆ 8. 이전에 발표했던 다른 조에 기간에 따른 룰을 정했었는지 물어봄.\n",
    "    \n",
    "- 빌표후반(모델링) :\n",
    "    - 샘플링 및 OLS : 첫 R2-0.71\n",
    "    - 첫 분석의 JB, QQ플롯 비교\n",
    "    - jointplot 시각화자료 보여줌 --> ◆ 9. R2의 집단이 두가지로 분화되는 이유를 우리가 ()때문이라고 판단한 근거가 무엇인지 물어봄(까였나?)\n",
    "    - 0인 데이터에 대한 insight를 말하고 다음 분석모델을 보여줌 --> ◆ 10. 그럼 0인 데이터는 어떻게 전처리 했는지 물어봄 - 0 빼버렸다고 대답 - 수긍함\n",
    "- 결론을 말하고 마무리함 --> ◆ 11. 수요/공급/재고와 같은 발언에 매우 민감하게 반응 - 아마도 분석결과만으로 이런 결론을 도출하기엔 설득력이 떨어진다고 생각했을듯.'\n",
    "\n",
    "\n",
    "- 아쉬운점 : CV에 대한 검증언급이 없었음, 이전에 쓴 다른 툴의 실패사례가 없었음\n",
    "\n",
    "\n",
    "# ■ 분석에서 중요한 3가지\n",
    "\n",
    "1. 이해 : 듣는사람이 이해하기 쉬워야한다.\n",
    "    - 발표용으로 정리해야한다\n",
    "    - 플롯 출력할때도 보는사람 생각해서 출력해야한다. (글꼴이나 플롯사이즈, 색상 등)\n",
    "2. 신뢰 : 믿음을 주어야 한다.\n",
    "    - 코드공개 ==> 실력을 보여줌 + 신뢰성 향상 (실수가 없다면 가산점!)\n",
    "    - 말실수를 조심해야한다. 다 잃을 수 있다.\n",
    "3. 성능 : 분석한 사람의 노력과 들인 시간에 비례\n",
    "    - 노력과, 시간, 횟수 등은 실제 성능에도 큰 영향을 미친다.\n",
    "\n",
    "- 기타 : 시계열의 원칙\n",
    "    - 보통의 시계열은 미래를 예측하는게 원칙\n",
    "    - 트레인용 과거 데이터가 중간에 비거나 하는 경우는 드물다. 정확한 트레인을 위해서도 일종의 약속과도 같다.\n",
    "    - 중간중간 데이터가 잘려있는 등의 일은 거의 있을 수 없다.(해석이 불가능해짐)\n",
    "    - 단. 몇몇군데만 비어있다면 그 빈곳 자체를 시계열분석으로 채워서 예측해볼수는 있다.\n",
    "    \n",
    "- zillow는 고난도 분석 -- 회사가 나쁜놈 -- 보통 이런 자료는 비선형으로 공략해야하며, 복잡도가 높은 모델을 쓰면 대형회사의 공장형 분석툴은 이길 수 있음\n",
    "- walmart는 저난도 분석 -- 회사가 게으름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 1. 데이터상태 분석하기(통계분석, data mining, 빅데이터분석)\n",
    "\n",
    "\n",
    "### 데이터를 보는 관점 (빅스터 이현종 대표 강의 중....)\n",
    "- 통계분석적 관점 -- 모수가 보이지 않으니 샘플체취 (100명을 뽑아서 10000명을 추측한다)\n",
    "- 빅데이터 관점 -- 이미 모수가 있고, 엄청난양을 빅데이터 분석함 (샘플체취 필요없음, 분류와 군집을 찾는일)\n",
    "- 하이브리드 분석 --  빅데이터로 패턴을 찾고 그 부분에서 샘플을 채취하여 통계분석.\n",
    "\n",
    "\n",
    "### 데이터의 유형 - [소스유형, 활용방향, 데이터형태, 저장구조]\n",
    "\n",
    "- **`소스유형`**\n",
    "    - 휴먼빅데이터 : 사람의 활동에 의해 발생하는 데이터\n",
    "        - (ERP기업내부, MES제조, SCM물류, VOC고객센터, 등) ==? CRM, BI/DW...\n",
    "    - 시스템(로그)빅데이터 : 기계, 머신 등의 로그기록\n",
    "        - 행태(스마트폰[통화기록 등] 등)\n",
    "        - 상태(IOT)\n",
    "    - 소셜(웹) 빅데이터 : 뉴스 등...\n",
    "    \n",
    "- **`활동방향`**\n",
    "    - 종류 : **현황분석(있다는걸 안다), 진단분석(원인을 안다), 예측분석(미리안다), 최적화분석(정확성을 높인다)**\n",
    "    - 늘리는 방향 : 원인 파악 등 --> 이윤창출 등 전략구사\n",
    "    - 줄이는 방향 : 진단 등 --> 비용절감, 암발생 예측 등\n",
    "    - 현상을 파악하는 방향 : 정확하게 or 빠르게 or 단순한 현상, 아는것(버스도착시간 지하철 시간 등)\n",
    "    \n",
    "- **`데이터 형태`**\n",
    "    - 정형 : 휴먼빅데이터류(고객센터 제외)\n",
    "    - 반정형 : log, XML\n",
    "    - 비정형 : 소셜, VOC(고객센터 등)\n",
    "    >- 나누는 방법 \n",
    "        - 형태가 있으면서 모든 데이터가 처리되고 계산 가능하면 정형데이터\n",
    "        - 형태는 있는데 바로 계산이 어려우면 비정형 (정제과정 필요)\n",
    "        - 형태도 모호하고 바로 분석도 어려우면 비정형 (텍스트, 이미지, 사운드, 영상 등)\n",
    "        \n",
    "- **`저장형태`**\n",
    "     - RDBMS\n",
    "     - FILE\n",
    "     - NoSQL\n",
    "         -몽고DB\n",
    "         -하둡 Hbase\n",
    "             \n",
    ">- 소량화된 데이터 : R로 분석\n",
    ">- 대량화된 데이터 : 파이썬 자바 등 프로그램으로\n",
    ">- 자동화 : 프로그램 사용\n",
    "\n",
    "\n",
    "\n",
    "### 데이터분석 4단계\n",
    "- 1) **`현황분석`** - 데이터 수집 및 데이터 상태 분석 <--**EDA**\n",
    "- 2) **`진단분석`** - **패턴**이 도출되는 과정, 변수의 가중치와 y절편을 찾는다.**(대부분 이걸 안하고 못해서 망한다)**\n",
    "      - 이때 모델이 완성된다, **여기까지가 통계분석적인 접근임**\n",
    "- 3) **`예측분석`** - 모델에 따른 예측값이 나온다, 지속적이고 자동화된 예측 <-- **여기는 머신러닝이다.**\n",
    "- 4) **`최적화분석`**\n",
    "\n",
    "- 지도학습에서 classification 이 인기가 있다. ==> 이게 거의 예측기법과 동일시 된다\n",
    "\n",
    "- 딥러닝 => 비지도. 분류시도. 음... 스스로 알아낼 수 있다고 거의 확실시됨. 그러나 성능이 좋은 컴퓨팅이 필요..\n",
    "\n",
    "### 분석의 5가지 의미\n",
    "- 1) **`일치여부`** : 실시간 분석 - CEP기술 (스파크)\n",
    "- 2) **`검색`** : 빨리 찾아야함(이것도 분석으로 분류되어가고있다)(스플렁크-데이터를 빨리 집계하게 해주는 기술)\n",
    "- 3) **`조회`** : 특정값 조회(하이브, SQL)\n",
    "- 4) **`연산`** : 연산도 능력 (맵리듀스,스파크 sql)\n",
    "- 5) **`분석`** : 사람이 할일 (R, Python --> 데이터 마이닝/머신러닝 관점에서 유리함)\n",
    "    - tip : 모델링까지는 R을 쓰는게 좋고, 그 이후 시스템적 접근은 파이썬으로 하세요.\n",
    "    \n",
    "\n",
    "# 2. EDA\n",
    "\n",
    "\n",
    "\n",
    "# 3. 데이터 전처리(변수 전처리)\n",
    "\n",
    "# 4. 분석용 데이터 추가\n",
    "\n",
    "# 5. 재분류\n",
    "\n",
    "# 6. 변수간 상관성 분석 or 시계열 판단\n",
    "\n",
    "# 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
